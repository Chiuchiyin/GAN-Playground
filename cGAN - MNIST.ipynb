{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN with MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "keras               2.10.0\n",
       "matplotlib          3.8.0\n",
       "numpy               1.26.4\n",
       "pandas              2.1.4\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                                         10.2.0\n",
       "aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42    NA\n",
       "absl                                        NA\n",
       "anyio                                       NA\n",
       "asttokens                                   NA\n",
       "astunparse                                  1.6.3\n",
       "attr                                        23.1.0\n",
       "attrs                                       23.1.0\n",
       "babel                                       2.11.0\n",
       "botocore                                    1.31.64\n",
       "bottleneck                                  1.3.7\n",
       "brotli                                      1.0.9\n",
       "certifi                                     2024.07.04\n",
       "cffi                                        1.16.0\n",
       "chardet                                     4.0.0\n",
       "charset_normalizer                          2.0.4\n",
       "cloudpickle                                 2.2.1\n",
       "colorama                                    0.4.6\n",
       "comm                                        0.1.2\n",
       "cycler                                      0.10.0\n",
       "cython_runtime                              NA\n",
       "dateutil                                    2.8.2\n",
       "debugpy                                     1.6.7\n",
       "decorator                                   5.1.1\n",
       "defusedxml                                  0.7.1\n",
       "dill                                        0.3.7\n",
       "exceptiongroup                              1.2.0\n",
       "executing                                   0.8.3\n",
       "fastjsonschema                              NA\n",
       "flatbuffers                                 24.3.25\n",
       "fsspec                                      2023.10.0\n",
       "gast                                        NA\n",
       "google                                      NA\n",
       "h5py                                        3.9.0\n",
       "idna                                        3.4\n",
       "ipykernel                                   6.28.0\n",
       "jedi                                        0.18.1\n",
       "jinja2                                      3.1.3\n",
       "json5                                       NA\n",
       "jsonpointer                                 2.1\n",
       "jsonschema                                  4.19.2\n",
       "jsonschema_specifications                   NA\n",
       "jupyter_events                              0.8.0\n",
       "jupyter_server                              2.10.0\n",
       "jupyterlab_server                           2.25.1\n",
       "kiwisolver                                  1.4.4\n",
       "lz4                                         4.3.2\n",
       "markupsafe                                  2.1.3\n",
       "matplotlib_inline                           0.1.6\n",
       "mkl                                         2.4.0\n",
       "mpl_toolkits                                NA\n",
       "nbformat                                    5.9.2\n",
       "nt                                          NA\n",
       "numexpr                                     2.8.7\n",
       "opt_einsum                                  v3.3.0\n",
       "overrides                                   NA\n",
       "packaging                                   23.1\n",
       "parso                                       0.8.3\n",
       "pickleshare                                 0.7.5\n",
       "pkg_resources                               NA\n",
       "platformdirs                                3.10.0\n",
       "prometheus_client                           NA\n",
       "prompt_toolkit                              3.0.43\n",
       "psutil                                      5.9.0\n",
       "pure_eval                                   0.2.2\n",
       "pyarrow                                     14.0.2\n",
       "pydev_ipython                               NA\n",
       "pydevconsole                                NA\n",
       "pydevd                                      2.9.5\n",
       "pydevd_file_utils                           NA\n",
       "pydevd_plugins                              NA\n",
       "pydevd_tracing                              NA\n",
       "pygments                                    2.15.1\n",
       "pyparsing                                   3.0.9\n",
       "pythoncom                                   NA\n",
       "pythonjsonlogger                            NA\n",
       "pytz                                        2023.3.post1\n",
       "pywin32_system32                            NA\n",
       "pywintypes                                  NA\n",
       "referencing                                 NA\n",
       "requests                                    2.31.0\n",
       "rfc3339_validator                           0.1.4\n",
       "rfc3986_validator                           0.1.1\n",
       "rpds                                        NA\n",
       "ruamel                                      NA\n",
       "scipy                                       1.11.4\n",
       "send2trash                                  NA\n",
       "setuptools                                  69.2.0\n",
       "six                                         1.16.0\n",
       "snappy                                      NA\n",
       "sniffio                                     1.3.0\n",
       "socks                                       1.7.1\n",
       "sphinxcontrib                               NA\n",
       "stack_data                                  0.2.0\n",
       "tblib                                       1.7.0\n",
       "tensorboard                                 2.10.1\n",
       "tensorflow                                  2.10.1\n",
       "termcolor                                   NA\n",
       "tornado                                     6.3.3\n",
       "traitlets                                   5.7.1\n",
       "typing_extensions                           NA\n",
       "urllib3                                     2.0.7\n",
       "wcwidth                                     0.2.5\n",
       "websocket                                   0.58.0\n",
       "win32api                                    NA\n",
       "win32com                                    NA\n",
       "win32con                                    NA\n",
       "win32trace                                  NA\n",
       "winerror                                    NA\n",
       "wrapt                                       1.14.1\n",
       "yaml                                        6.0.1\n",
       "zmq                                         25.1.2\n",
       "zoneinfo                                    NA\n",
       "zope                                        NA\n",
       "zstandard                                   0.19.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.20.0\n",
       "jupyter_client      8.6.0\n",
       "jupyter_core        5.5.0\n",
       "jupyterlab          4.0.11\n",
       "notebook            7.0.8\n",
       "-----\n",
       "Python 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.22631-SP0\n",
       "-----\n",
       "Session information updated at 2024-10-24 15:56\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "#import tensorflow as tf\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import (Activation, BatchNormalization, Concatenate, Dense,\n",
    "                          Embedding, Flatten, Input, Multiply, Reshape, Dropout)\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed using keras.utils.set_random_seed. This will set:\n",
    "# 1) `numpy` seed\n",
    "# 2) backend random seed\n",
    "# 3) `python` random seed\n",
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "#tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "\n",
    "# Input image dimensions\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# Size of the noise vector, used as input to the Generator\n",
    "z_dim = 100\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(z_dim):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Reshape input into 7x7x256 tensor via a fully connected layer\n",
    "    model.add(Dense(256 * 7 * 7, input_dim=z_dim))\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "    # Transposed convolution layer, from 7x7x256 into 14x14x128 tensor\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Transposed convolution layer, from 14x14x128 to 14x14x64 tensor\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Transposed convolution layer, from 14x14x64 to 28x28x1 tensor\n",
    "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # Output layer with tanh activation\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cgan_generator(z_dim):\n",
    "\n",
    "    # Random noise vector z\n",
    "    z = Input(shape=(z_dim, ))\n",
    "\n",
    "    # Conditioning label: integer 0-9 specifying the number G should generate\n",
    "    label = Input(shape=(1, ), dtype='int32')\n",
    "\n",
    "    # Label embedding:\n",
    "    # ----------------\n",
    "    # Turns labels into dense vectors of size z_dim\n",
    "    # Produces 3D tensor with shape (batch_size, 1, z_dim)\n",
    "    label_embedding = Embedding(num_classes, z_dim, input_length=1)(label)\n",
    "\n",
    "    # Flatten the embedding 3D tensor into 2D tensor with shape (batch_size, z_dim)\n",
    "    label_embedding = Flatten()(label_embedding)\n",
    "\n",
    "    # Element-wise product of the vectors z and the label embeddings\n",
    "    joined_representation = Multiply()([z, label_embedding])\n",
    "\n",
    "    generator = build_generator(z_dim)\n",
    "\n",
    "    # Generate image for the given label\n",
    "    conditioned_img = generator(joined_representation)\n",
    "\n",
    "    return Model([z, label], conditioned_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional layer, from 28x28x2 into 14x14x64 tensor\n",
    "    model.add(\n",
    "        Conv2D(64,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               input_shape=(img_shape[0], img_shape[1], img_shape[2] + 1),\n",
    "               padding='same'))\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Convolutional layer, from 14x14x64 into 7x7x64 tensor\n",
    "    model.add(\n",
    "        Conv2D(64,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               input_shape=img_shape,\n",
    "               padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    #model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU activation\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Convolutional layer, from 7x7x64 tensor into 3x3x128 tensor\n",
    "    model.add(\n",
    "        Conv2D(128,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               input_shape=img_shape,\n",
    "               padding='same'))\n",
    "\n",
    "    # Batch normalization\n",
    "    #model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Output layer with sigmoid activation\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cgan_discriminator(img_shape):\n",
    "\n",
    "    # Input image\n",
    "    img = Input(shape=img_shape)\n",
    "\n",
    "    # Label for the input image\n",
    "    label = Input(shape=(1, ), dtype='int32')\n",
    "\n",
    "    # Label embedding:\n",
    "    # ----------------\n",
    "    # Turns labels into dense vectors of size z_dim\n",
    "    # Produces 3D tensor with shape (batch_size, 1, 28*28*1)\n",
    "    label_embedding = Embedding(num_classes,\n",
    "                                np.prod(img_shape),\n",
    "                                input_length=1)(label)\n",
    "\n",
    "    # Flatten the embedding 3D tensor into 2D tensor with shape (batch_size, 28*28*1)\n",
    "    label_embedding = Flatten()(label_embedding)\n",
    "\n",
    "    # Reshape label embeddings to have same dimensions as input images\n",
    "    label_embedding = Reshape(img_shape)(label_embedding)\n",
    "\n",
    "    # Concatenate images with their label embeddings\n",
    "    concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
    "\n",
    "    discriminator = build_discriminator(img_shape)\n",
    "\n",
    "    # Classify the image-label pair\n",
    "    classification = discriminator(concatenated)\n",
    "\n",
    "    return Model([img, label], classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cgan(generator, discriminator):\n",
    "\n",
    "    # Random noise vector z\n",
    "    z = Input(shape=(z_dim, ))\n",
    "\n",
    "    # Image label\n",
    "    label = Input(shape=(1, ))\n",
    "\n",
    "    # Generated image for that label\n",
    "    img = generator([z, label])\n",
    "\n",
    "    classification = discriminator([img, label])\n",
    "\n",
    "    # Combined Generator -> Discriminator model\n",
    "    # G([z, lablel]) = x*\n",
    "    # D(x*) = classification\n",
    "    model = Model([z, label], classification)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the Discriminator\n",
    "discriminator = build_cgan_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Build the Generator\n",
    "generator = build_cgan_generator(z_dim)\n",
    "\n",
    "# Keep Discriminatorâ€™s parameters constant for Generator training\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Build and compile CGAN model with fixed Discriminator to train the Generator\n",
    "cgan = build_cgan(generator, discriminator)\n",
    "cgan.compile(loss='binary_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "\n",
    "def train(iterations, batch_size, sample_interval):\n",
    "\n",
    "    # Load the MNIST dataset\n",
    "    (X_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
    "    X_train = X_train / 127.5 - 1.\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    # Labels for real images: all ones\n",
    "    real = np.ones((batch_size, 1))\n",
    "\n",
    "    # Labels for fake images: all zeros\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "\n",
    "        # -------------------------\n",
    "        #  Train the Discriminator\n",
    "        # -------------------------\n",
    "\n",
    "        # Get a random batch of real images and their labels\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs, labels = X_train[idx], y_train[idx]\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        gen_imgs = generator.predict([z, labels], verbose=0)\n",
    "\n",
    "        # Train the Discriminator\n",
    "        d_loss_real = discriminator.train_on_batch([imgs, labels], real)\n",
    "        d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train the Generator\n",
    "        # ---------------------\n",
    "\n",
    "        # Generate a batch of noise vectors\n",
    "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "\n",
    "        # Get a batch of random labels\n",
    "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
    "\n",
    "        # Train the Generator\n",
    "        g_loss = cgan.train_on_batch([z, labels], real)\n",
    "\n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "\n",
    "            # Output training progress\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
    "                  (iteration + 1, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "            # Save losses and accuracies so they can be plotted after training\n",
    "            losses.append((d_loss[0], g_loss))\n",
    "            accuracies.append(100 * d_loss[1])\n",
    "\n",
    "            # Output sample of generated images\n",
    "            sample_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(image_grid_rows=2, image_grid_columns=5):\n",
    "\n",
    "    # Sample random noise\n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "\n",
    "    # Get image labels 0-9\n",
    "    labels = np.arange(0, 10).reshape(-1, 1)\n",
    "\n",
    "    # Generate images from random noise\n",
    "    gen_imgs = generator.predict([z, labels], verbose=0)\n",
    "\n",
    "    # Rescale image pixel values to [0, 1]\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    # Set image grid\n",
    "    fig, axs = plt.subplots(image_grid_rows,\n",
    "                            image_grid_columns,\n",
    "                            figsize=(10, 4),\n",
    "                            sharey=True,\n",
    "                            sharex=True)\n",
    "\n",
    "    cnt = 0\n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_columns):\n",
    "            # Output a grid of images\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            axs[i, j].set_title(\"Digit: %d\" % labels[cnt])\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model and Inspect Training Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `'Discrepancy between trainable weights and collected trainable'` warning from Keras is expected. It is by design: The Generator's trainable parameters are intentionally held constant during Discriminator training, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "iterations = 20000\n",
    "batch_size = 512\n",
    "sample_interval = 1000\n",
    "\n",
    "# Train the CGAN for the specified number of iterations\n",
    "train(iterations, batch_size, sample_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output from a Trained CGAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set grid dimensions\n",
    "image_grid_rows = 10\n",
    "image_grid_columns = 5\n",
    "\n",
    "# Sample random noise\n",
    "z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "\n",
    "# Get image labels to generate: 5 samples for each label\n",
    "labels_to_generate = np.array([[i for j in range(5)] for i in range(10)])\n",
    "labels_to_generate = labels_to_generate.flatten().reshape(-1, 1)\n",
    "\n",
    "# Generate images from random noise\n",
    "gen_imgs = generator.predict([z, labels_to_generate])\n",
    "\n",
    "# Rescale image pixel values to [0, 1]\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "# Set image grid\n",
    "fig, axs = plt.subplots(image_grid_rows,\n",
    "                        image_grid_columns,\n",
    "                        figsize=(10, 20),\n",
    "                        sharey=True,\n",
    "                        sharex=True)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(image_grid_rows):\n",
    "    for j in range(image_grid_columns):\n",
    "        # Output a grid of images\n",
    "        axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].set_title(\"Digit: %d\" % labels_to_generate[cnt])  ## NEW\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is too alert me when it finishes\n",
    "import winsound \n",
    " \n",
    "# frequency is set to 524Hz\n",
    "freq = 524\n",
    " \n",
    "# duration is set to 1.5 seconds             \n",
    "dur = 1500\n",
    "              \n",
    "winsound.Beep(freq, dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart-beat",
   "language": "python",
   "name": "heart-beat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
